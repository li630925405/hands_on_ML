{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To support both python 2 and python 3\n",
    "from __future__ import division, print_function, unicode_literals\n",
    "\n",
    "# Common imports\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "def reset_graph(seed=42):\n",
    "    tf.reset_default_graph()\n",
    "    tf.set_random_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['axes.labelsize'] = 14\n",
    "plt.rcParams['xtick.labelsize'] = 12\n",
    "plt.rcParams['ytick.labelsize'] = 12\n",
    "\n",
    "# Where to save the figures\n",
    "PROJECT_ROOT_DIR = \".\"\n",
    "CHAPTER_ID = \"tensorflow\"\n",
    "\n",
    "def save_fig(fig_id, tight_layout=True):\n",
    "    path = os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID, fig_id + \".png\")\n",
    "    print(\"Saving figure\", fig_id)\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format='png', dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Logistic Regression with Mini-Batch Gradient Descent using TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's create the moons dataset using Scikit-Learn's `make_moons()` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_moons\n",
    "\n",
    "m = 1000\n",
    "X_moons, y_moons = make_moons(m, noise=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_moons_with_bias = np.c_[np.ones((m, 1)), X_moons]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_moons_column_vector = y_moons.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ratio = 0.2\n",
    "test_size = int(m * test_ratio)\n",
    "X_train = X_moons_with_bias[:-test_size]\n",
    "X_test = X_moons_with_bias[-test_size:]\n",
    "y_train = y_moons_column_vector[:-test_size]\n",
    "y_test = y_moons_column_vector[-test_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_batch(X_train, y_train, batch_size):\n",
    "    rnd_indices = np.random.randint(0, len(X_train), batch_size)\n",
    "    X_batch = X_train[rnd_indices]\n",
    "    y_batch = y_train[rnd_indices]\n",
    "    return X_batch, y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Users\\63092\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "\n",
    "reset_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The _moons_ dataset has two input features, since each instance is a point on a plane (i.e., 2-Dimensional):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_inputs = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's build the Logistic Regression model. As we saw in chapter 4, this model first computes a weighted sum of the inputs (just like the Linear Regression model), and then it applies the sigmoid function to the result, which gives us the estimated probability for the positive class:\n",
    "\n",
    "$\\hat{p} = h_\\boldsymbol{\\theta}(\\mathbf{x}) = \\sigma(\\boldsymbol{\\theta}^T \\mathbf{x})$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that $\\boldsymbol{\\theta}$ is the parameter vector, containing the bias term $\\theta_0$ and the weights $\\theta_1, \\theta_2, \\dots, \\theta_n$. The input vector $\\mathbf{x}$ contains a constant term $x_0 = 1$, as well as all the input features $x_1, x_2, \\dots, x_n$.\n",
    "\n",
    "Since we want to be able to make predictions for multiple instances at a time, we will use an input matrix $\\mathbf{X}$ rather than a single input vector. The $i^{th}$ row will contain the transpose of the $i^{th}$ input vector $(\\mathbf{x}^{(i)})^T$. It is then possible to estimate the probability that each instance belongs to the positive class using the following equation:\n",
    "\n",
    "$ \\hat{\\mathbf{p}} = \\sigma(\\mathbf{X} \\boldsymbol{\\theta})$\n",
    "\n",
    "That's all we need to build the model:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In fact, TensorFlow has a nice function `tf.sigmoid()` that we can use to simplify the last line of the previous code:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we saw in chapter 4, the log loss is a good cost function to use for Logistic Regression:\n",
    "\n",
    "$J(\\boldsymbol{\\theta}) = -\\dfrac{1}{m} \\sum\\limits_{i=1}^{m}{\\left[ y^{(i)} \\log\\left(\\hat{p}^{(i)}\\right) + (1 - y^{(i)}) \\log\\left(1 - \\hat{p}^{(i)}\\right)\\right]}$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's start over, but this time we will add all the bells and whistles, as listed in the exercise:\n",
    "* Define the graph within a `logistic_regression()` function that can be reused easily.\n",
    "* Save checkpoints using a `Saver` at regular intervals during training, and save the final model at the end of training.\n",
    "* Restore the last checkpoint upon startup if training was interrupted.\n",
    "* Define the graph using nice scopes so the graph looks good in TensorBoard.\n",
    "* Add summaries to visualize the learning curves in TensorBoard.\n",
    "* Try tweaking some hyperparameters such as the learning rate or the mini-batch size and look at the shape of the learning curve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_enhanced = np.c_[X_train,\n",
    "                         np.square(X_train[:, 1]),\n",
    "                         np.square(X_train[:, 2]),\n",
    "                         X_train[:, 1] ** 3,\n",
    "                         X_train[:, 2] ** 3]\n",
    "X_test_enhanced = np.c_[X_test,\n",
    "                        np.square(X_test[:, 1]),\n",
    "                        np.square(X_test[:, 2]),\n",
    "                        X_test[:, 1] ** 3,\n",
    "                        X_test[:, 2] ** 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_regression(X, y, initializer=None, seed=42, learning_rate=0.01):\n",
    "    n_inputs_including_bias = int(X.get_shape()[1])\n",
    "    with tf.name_scope(\"logistic_regression\"):\n",
    "        with tf.name_scope(\"model\"):\n",
    "            if initializer is None:\n",
    "                initializer = tf.random_uniform([n_inputs_including_bias, 1], -1.0, 1.0, seed=seed)\n",
    "            theta = tf.Variable(initializer, name=\"theta\")\n",
    "            logits = tf.matmul(X, theta, name=\"logits\")\n",
    "            y_proba = tf.sigmoid(logits)\n",
    "        with tf.name_scope(\"train\"):\n",
    "            loss = tf.losses.log_loss(y, y_proba, scope=\"loss\")\n",
    "            optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "            training_op = optimizer.minimize(loss)\n",
    "            loss_summary = tf.summary.scalar('log_loss', loss)\n",
    "        with tf.name_scope(\"init\"):\n",
    "            init = tf.global_variables_initializer()\n",
    "        with tf.name_scope(\"save\"):\n",
    "            saver = tf.train.Saver()\n",
    "    return y_proba, loss, training_op, loss_summary, init, saver"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a little function to get the name of the log directory to save the summaries for Tensorboard:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "def log_dir(prefix=\"\"):\n",
    "    now = datetime.utcnow().strftime(\"%Y%m%d%H%M%S\")\n",
    "    root_logdir = \"tf_logs\"\n",
    "    if prefix:\n",
    "        prefix += \"-\"\n",
    "    name = prefix + \"run-\" + now\n",
    "    return \"{}/{}/\".format(root_logdir, name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's create the graph, using the `logistic_regression()` function. We will also create the `FileWriter` to save the summaries to the log directory for Tensorboard:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From E:\\Users\\63092\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From E:\\Users\\63092\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\losses\\losses_impl.py:514: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    }
   ],
   "source": [
    "n_inputs = 2 + 4\n",
    "logdir = log_dir(\"logreg\")\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs + 1), name=\"X\")\n",
    "y = tf.placeholder(tf.float32, shape=(None, 1), name=\"y\")\n",
    "\n",
    "y_proba, loss, training_op, loss_summary, init, saver = logistic_regression(X, y)\n",
    "\n",
    "file_writer = tf.summary.FileWriter(logdir, tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At last we can train the model! We will start by checking whether a previous training session was interrupted, and if so we will load the checkpoint and continue training from the epoch number we saved. In this example we just save the epoch number to a separate file, but in chapter 11 we will see how to store the training step directly as part of the model, using a non-trainable variable called `global_step` that we pass to the optimizer's `minimize()` method.\n",
    "\n",
    "You can try interrupting training to verify that it does indeed restore the last checkpoint when you start it again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 \tLoss: 0.62998503\n",
      "Epoch: 500 \tLoss: 0.16122366\n",
      "Epoch: 1000 \tLoss: 0.1190321\n",
      "Epoch: 1500 \tLoss: 0.097329214\n",
      "Epoch: 2000 \tLoss: 0.08369793\n",
      "Epoch: 2500 \tLoss: 0.07437582\n",
      "Epoch: 3000 \tLoss: 0.06750215\n",
      "Epoch: 3500 \tLoss: 0.062206898\n",
      "Epoch: 4000 \tLoss: 0.058026787\n",
      "Epoch: 4500 \tLoss: 0.05456297\n",
      "Epoch: 5000 \tLoss: 0.051708277\n",
      "Epoch: 5500 \tLoss: 0.04923773\n",
      "Epoch: 6000 \tLoss: 0.047167283\n",
      "Epoch: 6500 \tLoss: 0.045376644\n",
      "Epoch: 7000 \tLoss: 0.04381875\n",
      "Epoch: 7500 \tLoss: 0.042374235\n",
      "Epoch: 8000 \tLoss: 0.041089173\n",
      "Epoch: 8500 \tLoss: 0.039970923\n",
      "Epoch: 9000 \tLoss: 0.038920265\n",
      "Epoch: 9500 \tLoss: 0.038010757\n",
      "Epoch: 10000 \tLoss: 0.037155706\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 10001\n",
    "batch_size = 50\n",
    "n_batches = int(np.ceil(m / batch_size))\n",
    "\n",
    "# checkpoint_path = os.path.join(\"tmp\", \"my_logreg_model.ckpt\")\n",
    "checkpoint_path = \"my_logreg_model.ckpt\"\n",
    "checkpoint_epoch_path = checkpoint_path + \".epoch\"\n",
    "final_model_path = \"my_logreg_model\"\n",
    "\n",
    "with tf.Session(config=config) as sess:\n",
    "    if os.path.isfile(checkpoint_epoch_path):\n",
    "        with open(checkpoint_epoch_path, \"rb\") as f:\n",
    "            start_epoch = int(f.read())\n",
    "        print(\"Training was interrupted. Continuing at epoch\", start_epoch)\n",
    "        saver.restore(sess, checkpoint_path)\n",
    "    else:\n",
    "        start_epoch = 0\n",
    "        sess.run(init)\n",
    "\n",
    "    for epoch in range(start_epoch, n_epochs):\n",
    "        for batch_index in range(n_batches):\n",
    "            X_batch, y_batch = random_batch(X_train_enhanced, y_train, batch_size)\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        loss_val, summary_str = sess.run([loss, loss_summary], feed_dict={X: X_test_enhanced, y: y_test})\n",
    "        file_writer.add_summary(summary_str, epoch)\n",
    "        if epoch % 500 == 0:\n",
    "            print(\"Epoch:\", epoch, \"\\tLoss:\", loss_val)\n",
    "            saver.save(sess, checkpoint_path)\n",
    "            with open(checkpoint_epoch_path, \"wb\") as f:\n",
    "                f.write(b\"%d\" % (epoch + 1))\n",
    "\n",
    "    saver.save(sess, final_model_path)\n",
    "    y_proba_val = y_proba.eval(feed_dict={X: X_test_enhanced, y: y_test})\n",
    "    os.remove(checkpoint_epoch_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once again, we can make predictions by just classifying as positive all the instances whose estimated probability is greater or equal to 0.5:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = (y_proba_val >= 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9797979797979798"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score\n",
    "precision_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9797979797979798"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred_idx = y_pred.reshape(-1) # a 1D array rather than a column vector\n",
    "plt.plot(X_test[y_pred_idx, 1], X_test[y_pred_idx, 2], 'go', label=\"Positive\")\n",
    "plt.plot(X_test[~y_pred_idx, 1], X_test[~y_pred_idx, 2], 'r^', label=\"Negative\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try starting the tensorboard server, find the latest run and look at the learning curve (i.e., how the loss evaluated on the test set evolves as a function of the epoch number):\n",
    "\n",
    "```\n",
    "$ tensorboard --logdir=tf_logs\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can play around with the hyperparameters (e.g. the `batch_size` or the `learning_rate`) and run training again and again, comparing the learning curves. You can even automate this process by implementing grid search or randomized search. Below is a simple implementation of a randomized search on both the batch size and the learning rate. For the sake of simplicity, the checkpoint mechanism was removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from scipy.stats import reciprocal\n",
    "\n",
    "# n_search_iterations = 10\n",
    "\n",
    "# for search_iteration in range(n_search_iterations):\n",
    "#     batch_size = np.random.randint(1, 100)\n",
    "#     learning_rate = reciprocal(0.0001, 0.1).rvs(random_state=search_iteration)\n",
    "\n",
    "#     n_inputs = 2 + 4\n",
    "#     logdir = log_dir(\"logreg\")\n",
    "    \n",
    "#     print(\"Iteration\", search_iteration)\n",
    "#     print(\"  logdir:\", logdir)\n",
    "#     print(\"  batch size:\", batch_size)\n",
    "#     print(\"  learning_rate:\", learning_rate)\n",
    "#     print(\"  training: \", end=\"\")\n",
    "\n",
    "#     reset_graph()\n",
    "\n",
    "#     X = tf.placeholder(tf.float32, shape=(None, n_inputs + 1), name=\"X\")\n",
    "#     y = tf.placeholder(tf.float32, shape=(None, 1), name=\"y\")\n",
    "\n",
    "#     y_proba, loss, training_op, loss_summary, init, saver = logistic_regression(\n",
    "#         X, y, learning_rate=learning_rate)\n",
    "\n",
    "#     file_writer = tf.summary.FileWriter(logdir, tf.get_default_graph())\n",
    "\n",
    "#     n_epochs = 10001\n",
    "#     n_batches = int(np.ceil(m / batch_size))\n",
    "\n",
    "#     final_model_path = \"./my_logreg_model_%d\" % search_iteration\n",
    "\n",
    "#     with tf.Session() as sess:\n",
    "#         sess.run(init)\n",
    "\n",
    "#         for epoch in range(n_epochs):\n",
    "#             for batch_index in range(n_batches):\n",
    "#                 X_batch, y_batch = random_batch(X_train_enhanced, y_train, batch_size)\n",
    "#                 sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "#             loss_val, summary_str = sess.run([loss, loss_summary], feed_dict={X: X_test_enhanced, y: y_test})\n",
    "#             file_writer.add_summary(summary_str, epoch)\n",
    "#             if epoch % 500 == 0:\n",
    "#                 print(\".\", end=\"\")\n",
    "\n",
    "#         saver.save(sess, final_model_path)\n",
    "\n",
    "#         print()\n",
    "#         y_proba_val = y_proba.eval(feed_dict={X: X_test_enhanced, y: y_test})\n",
    "#         y_pred = (y_proba_val >= 0.5)\n",
    "        \n",
    "#         print(\"  precision:\", precision_score(y_test, y_pred))\n",
    "#         print(\"  recall:\", recall_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `reciprocal()` function from SciPy's `stats` module returns a random distribution that is commonly used when you have no idea of the optimal scale of a hyperparameter. See the exercise solutions for chapter 2 for more details. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
